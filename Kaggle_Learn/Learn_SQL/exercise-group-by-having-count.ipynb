{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":285982,"sourceType":"datasetVersion","datasetId":6057}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/group-by-having-count).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nQueries with **GROUP BY** can be powerful. There are many small things that can trip you up (like the order of the clauses), but it will start to feel natural once you've done it a few times. Here, you'll write queries using **GROUP BY** to answer questions from the Hacker News dataset.\n\nBefore you get started, run the following cell to set everything up:","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex3 import *\nprint(\"Setup Complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:06:23.128152Z","iopub.execute_input":"2025-05-24T05:06:23.128467Z","iopub.status.idle":"2025-05-24T05:06:44.569662Z","shell.execute_reply.started":"2025-05-24T05:06:23.128443Z","shell.execute_reply":"2025-05-24T05:06:44.568648Z"}},"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"The code cell below fetches the `full` table from the `hacker_news` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"full\" table\ntable_ref = dataset_ref.table(\"full\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:13:06.153790Z","iopub.execute_input":"2025-05-24T05:13:06.154358Z","iopub.status.idle":"2025-05-24T05:13:07.154698Z","shell.execute_reply.started":"2025-05-24T05:13:06.154330Z","shell.execute_reply":"2025-05-24T05:13:07.153816Z"}},"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  title   url  text  dead    by  score        time                 timestamp  \\\n0  None  None  None  <NA>  None   <NA>  1437779677 2015-07-24 23:14:37+00:00   \n1  None  None  None  <NA>  None   <NA>  1437782037 2015-07-24 23:53:57+00:00   \n2  None  None  None  <NA>  None   <NA>  1437783176 2015-07-25 00:12:56+00:00   \n3  None  None  None  <NA>  None   <NA>  1437783795 2015-07-25 00:23:15+00:00   \n4  None  None  None  <NA>  None   <NA>  1437784053 2015-07-25 00:27:33+00:00   \n\n    type       id  parent  descendants  ranking  deleted  \n0  story  9945806    <NA>         <NA>     <NA>     <NA>  \n1  story  9945926    <NA>         <NA>     <NA>     <NA>  \n2  story  9945992    <NA>         <NA>     <NA>     <NA>  \n3  story  9946018    <NA>         <NA>     <NA>     <NA>  \n4  story  9946026    <NA>         <NA>     <NA>     <NA>  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>text</th>\n      <th>dead</th>\n      <th>by</th>\n      <th>score</th>\n      <th>time</th>\n      <th>timestamp</th>\n      <th>type</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>1437779677</td>\n      <td>2015-07-24 23:14:37+00:00</td>\n      <td>story</td>\n      <td>9945806</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>1437782037</td>\n      <td>2015-07-24 23:53:57+00:00</td>\n      <td>story</td>\n      <td>9945926</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>1437783176</td>\n      <td>2015-07-25 00:12:56+00:00</td>\n      <td>story</td>\n      <td>9945992</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>1437783795</td>\n      <td>2015-07-25 00:23:15+00:00</td>\n      <td>story</td>\n      <td>9946018</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>None</td>\n      <td>&lt;NA&gt;</td>\n      <td>1437784053</td>\n      <td>2015-07-25 00:27:33+00:00</td>\n      <td>story</td>\n      <td>9946026</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n      <td>&lt;NA&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Prolific commenters\n\nHacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors with more than 10,000 posts as well as their post counts. Call the column with post counts `NumPosts`.\n\nIn case sample query is helpful, here is a query you saw in the tutorial to answer a similar question:\n```\nquery = \"\"\"\n        SELECT parent, COUNT(1) AS NumPosts\n        FROM `bigquery-public-data.hacker_news.full`\n        GROUP BY parent\n        HAVING COUNT(1) > 10\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select prolific commenters and post counts\nprolific_commenters_query = \"\"\"\n                            SELECT `by` AS author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.full`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"\n        \"\"\" # Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(prolific_commenters_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nprolific_commenters = query_job.to_dataframe()\n\n# View top few rows of results\nprint(prolific_commenters.head())\n\n# Check your answer\nq_1.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:39:33.054764Z","iopub.execute_input":"2025-05-24T05:39:33.055107Z","iopub.status.idle":"2025-05-24T05:39:34.278473Z","shell.execute_reply.started":"2025-05-24T05:39:33.055059Z","shell.execute_reply":"2025-05-24T05:39:34.277242Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/603830178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# API request - run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprolific_commenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# View top few rows of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \"\"\"\n\u001b[0;32m-> 2052\u001b[0;31m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2053\u001b[0m         return query_result.to_dataframe(\n\u001b[1;32m   2054\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001b[0m in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1623\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mForbidden\u001b[0m: 403 Access Denied: Table bigquery-public-data:hacker-news.full: User does not have permission to query table bigquery-public-data:hacker-news.full, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table bigquery-public-data:hacker-news.full: User does not have permission to query table bigquery-public-data:hacker-news.full, or perhaps it does not exist.\n\nLocation: US\nJob ID: 4ba7688d-c219-47e7-adff-f6d7df655a7d\n"],"ename":"Forbidden","evalue":"403 Access Denied: Table bigquery-public-data:hacker-news.full: User does not have permission to query table bigquery-public-data:hacker-news.full, or perhaps it does not exist.; reason: accessDenied, message: Access Denied: Table bigquery-public-data:hacker-news.full: User does not have permission to query table bigquery-public-data:hacker-news.full, or perhaps it does not exist.\n\nLocation: US\nJob ID: 4ba7688d-c219-47e7-adff-f6d7df655a7d\n","output_type":"error"}],"execution_count":15},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"q_1.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:40:05.879852Z","iopub.execute_input":"2025-05-24T05:40:05.880183Z","iopub.status.idle":"2025-05-24T05:40:05.887274Z","shell.execute_reply.started":"2025-05-24T05:40:05.880159Z","shell.execute_reply":"2025-05-24T05:40:05.886207Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"1_ProlificCommenters\", \"learnToolsVersion\": \"0.3.5\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nprolific_commenters_query = \"\"\"\n                            SELECT `by` AS author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.full`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nprolific_commenters_query = \"\"\"\n                            SELECT `by` AS author, COUNT(1) AS NumPosts\n                            FROM `bigquery-public-data.hacker_news.full`\n                            GROUP BY author\n                            HAVING COUNT(1) > 10000\n                            \"\"\"\n\n```"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"### 2) Deleted comments\n\nHow many comments have been deleted? (If a comment was deleted, the `deleted` column in the table will have the value `True`.)","metadata":{}},{"cell_type":"code","source":"# Write your query here and figure out the answer\ndeleted_posts_query = \"\"\"\n                      SELECT COUNT(1) AS num_deleted_posts\n                      FROM `bigquery-public-data.hacker_news.full`\n                      WHERE deleted = True\n                      \"\"\"\nquery_job = client.query(deleted_posts_query)\ndeleted_posts = query_job.to_dataframe()\nprint(deleted_posts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:39:48.391581Z","iopub.execute_input":"2025-05-24T05:39:48.391847Z","iopub.status.idle":"2025-05-24T05:39:49.224665Z","shell.execute_reply.started":"2025-05-24T05:39:48.391829Z","shell.execute_reply":"2025-05-24T05:39:49.223707Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"   num_deleted_posts\n0                  0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"num_deleted_posts = 0 # Put your answer here\n\n# Check your answer\nq_2.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:39:56.458527Z","iopub.execute_input":"2025-05-24T05:39:56.458819Z","iopub.status.idle":"2025-05-24T05:39:56.466913Z","shell.execute_reply.started":"2025-05-24T05:39:56.458798Z","shell.execute_reply":"2025-05-24T05:39:56.465916Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"2_NumDeletedPosts\", \"learnToolsVersion\": \"0.3.5\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"q_2.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T05:18:21.824902Z","iopub.execute_input":"2025-05-24T05:18:21.825234Z","iopub.status.idle":"2025-05-24T05:18:21.833058Z","shell.execute_reply.started":"2025-05-24T05:18:21.825210Z","shell.execute_reply":"2025-05-24T05:18:21.832400Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"questionId\": \"2_NumDeletedPosts\", \"learnToolsVersion\": \"0.3.5\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n# Query to determine how many posts were deleted\ndeleted_posts_query = \"\"\"\n                      SELECT COUNT(1) AS num_deleted_posts\n                      FROM `bigquery-public-data.hacker_news.full`\n                      WHERE deleted = True\n                      \"\"\"\n                      \n# Set up the query\nquery_job = client.query(deleted_posts_query)\n\n# API request - run the query, and return a pandas DataFrame\ndeleted_posts = query_job.to_dataframe()\n\n# View results\nprint(deleted_posts)\n\nnum_deleted_posts = 0\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n# Query to determine how many posts were deleted\ndeleted_posts_query = \"\"\"\n                      SELECT COUNT(1) AS num_deleted_posts\n                      FROM `bigquery-public-data.hacker_news.full`\n                      WHERE deleted = True\n                      \"\"\"\n                      \n# Set up the query\nquery_job = client.query(deleted_posts_query)\n\n# API request - run the query, and return a pandas DataFrame\ndeleted_posts = query_job.to_dataframe()\n\n# View results\nprint(deleted_posts)\n\nnum_deleted_posts = 0\n\n```"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Keep Going\n**[Click here](https://www.kaggle.com/dansbecker/order-by)** to move on and learn about the **ORDER BY** clause.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}